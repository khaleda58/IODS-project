---
title: "chapter4.Rmd"
subtitle: Khaleda Begum
date: "2023-11-26"
name: Khaleda Begum
---

# Assignment 4
## Claustering and classification
### Step 2: Data loading

```{r, message=FALSE, warning=FALSE}

library(MASS)

# load the data
data("Boston")

# explore the dataset
dim(Boston)
str(Boston)

```

This data set contains 506 observation and 14 variables. The data represents different features of the city such as crim is per capital crime rate per town, zn is proportion of residential land zoned for lots over 25,000 sq.ft., indus is proportion of non-retail business acres per town, chas is Charles River dummy variable (= 1 if tract bounds river; 0 otherwise), nox is nitrogen oxides concentration (parts per 10 million), rm is average number of rooms per dwelling.age is proportion of owner-occupied units built prior to 1940, dis is weighted mean of distances to five Boston employment centres, rad is index of accessibility to radial highways, tax is full-value property-tax rate per $10,000, patratio is pupil-teacher ratio by town, lastat is lower status of the population (percent), medv is median value of owner-occupied homes in $1000s.

### Step 3: Graphical pesentation and summaries of data:
```{r, message=FALSE, warning==FALSE, echo=FALSE}
#Summary of the data:
summary(Boston)

#Graphical presentation of data through pair plot
panel.cor <- function(x, y, ...){
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- round(cor(x, y), digits=2)
  txt <- paste0("R = ", r)
  cex.cor <- 0.8/strwidth(txt) #if want to adjust text size based on R value
  text(0.5, 0.5, txt, cex = 1)} #if adjusting; cex=cex.cor

#Function for adding regression line
upper_panel_regression_line = function(x,y, ...){
  points(x,y,...)
  linear_regression = lm(y~x)
  linear_regression_line = abline(linear_regression)}

my_cols <- c("#00AFBB", "#E7B800") #set colors


#for being able to change color, convert gender to factor type

#Visualization with a scatter plot + regression line matrix, add R values to the lower side of the matrix.
pairs(Boston, col = my_cols[Boston$chas],
      lower.panel = panel.cor , upper.panel = upper_panel_regression_line)


#Correlations plot

library(corrplot)
# calculate the correlation matrix and round it
cor_matrix <- cor(Boston)

# print the correlation matrix
cor_matrix

# visualize the correlation matrix
library(corrplot)
corrplot(cor_matrix, method="circle")

```
### Step 4: Standardizing the data:
```{r, echo=FALSE}
#scaling of the data
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)

#creating a categorical variable
boston_scaled$crim <- as.numeric(boston_scaled$crim)

# creating a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
bins

# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, 
             labels = c("low","med_low","med_high","high"),
             include.lowest = TRUE)
crime
# look at the table of the new factor crime
table(crime)

# removing original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
  
# adding the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
boston_scaled$crime <- factor(boston_scaled$crime, levels = c("low", "med_low", "med_high", "high"))

#Dividing the data set into training and test
# number of rows in the Boston dataset 
n <- nrow(boston_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test$crime

# remove the crime variable from test data
test <- dplyr::select(test, -crime)

```

### Step 5: Linear discriminant analyis

```{r, message=FALSE}

# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)

# print the lda.fit object
lda.fit

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  graphics::arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results (select both lines and execute them at the same time!)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)

```

### Step 6: Prediction of LDA
```{r}
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = lda.pred$class, predicted = lda.pred$class)

```


### Step 7: Distance measurement

```{r, warning=FALSE}
library(ggplot2)

scaled_boston <- scale(Boston)

# euclidean distance matrix
dist_eu <- dist(scaled_boston)

# looking at the summary of the distances
summary(dist_eu)

# manhattan distance matrix
dist_man <- dist(scaled_boston, method = "manhattan")
summary(dist_man)

#K-means clustering

set.seed(13)
km <- kmeans(scaled_boston, centers = 4)
pairs(scaled_boston[,6:10], col = km$cluster)

km1 <- kmeans(scaled_boston, centers = 3)
pairs(scaled_boston[,6:10], col = km1$cluster)

# Determining optimul number of clustering
set.seed(123)

# determine the number of clusters
k_max <- 10

# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(scaled_boston, k)$tot.withinss})

# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')

#here WCSS changes radically approximately from 2, that is why optimul cluster seems to be 2 
# k-means clustering
km_final <- kmeans(scaled_boston, centers = 2)

# ploting the dataset with clusters
pairs(scaled_boston, col = km_final$cluster)

```

### Bonus
```{r}
library(MASS)
km2 <- kmeans(scaled_boston, centers = 3)
pairs(scaled_boston, col = km2$cluster)

scaled_boston <- as.data.frame(scaled_boston)
lda.fit.1 <- lda(crim ~ ., data = scaled_boston)

plot(lda.fit.1, dimen = 2, col = as.numeric(scaled_boston$crim), 
     pch = as.numeric(scaled_boston$crim))
lda.arrows(lda.fit.1, myscale = 1)

```


